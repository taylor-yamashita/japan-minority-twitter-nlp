{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from typing import List\n",
    "import twscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_directories(keyword_eng: str, year: str):\n",
    "    os.mkdir(keyword_eng + \"_\" + year)\n",
    "\n",
    "    # single digit month\n",
    "    for i in range(1,10):\n",
    "        path = keyword_eng + \"_\" + year + \"/\" + \"0\" + str(i)\n",
    "        os.mkdir(path) \n",
    "\n",
    "    # double digit month\n",
    "    for j in range(10,13):\n",
    "        path = keyword_eng + \"_\" + year + \"/\" + str(j)\n",
    "        os.mkdir(path) \n",
    "\n",
    "set_up_directories(\"test\", \"2001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove directories if needed\n",
    "# !rm -rf test_2001/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect tweets for 10 randomly sampled days of month at randomly sampled time of day\n",
    "def scrape_sampled_tweets(year: str, months: List[str], days_in_month: int, keyword_jp=\"\", keyword_eng=\"\"):\n",
    "    range_days = list(range(1,days_in_month+1))\n",
    "    range_times = list(range(0,24))\n",
    "    dir_path = year if keyword_eng == \"\" else keyword_eng + \"_\" + year\n",
    "\n",
    "    # sample 10 random days and times of day for each month\n",
    "    for m in months: \n",
    "        month_path = dir_path + \"/\" + year + \"-\" + m\n",
    "        days = sorted(random.sample(range_days, k=10))   # random days of month (no replacement)\n",
    "        times = random.choices(range_times, k=10)   # random hours of day (replacement)\n",
    "        \n",
    "        # scrape tweets for the 10 picked days and times\n",
    "        for t in range(10):     \n",
    "            day = \"0\" + str(days[t]) if days[t] < 10 else str(days[t])\n",
    "            time = \"0\" + str(times[t]) if times[t] < 10 else str(times[t])\n",
    "            day_path = month_path + \"/\" + year + \"-\" + m + \"-\" + day + \".txt\"\n",
    "            command = 'twscrape search \"' + keyword_jp + ' since:' + year + '-' + m + '-' + day + '_' + time + ':00:00_UTC lang:ja\"　> ' + day_path + ' --limit=4500'\n",
    "            os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_txt_files(year: str, keyword_eng=\"\"):\n",
    "  # concatenate .txt files into one file per month\n",
    "  for root, dirs, files in os.walk(\"./\" + year):\n",
    "      for name in dirs:\n",
    "        month_path = os.path.join(root, name)\n",
    "        os.system(\"cat \" + month_path + \"/*.txt > \" + name + \".txt\")\n",
    "  \n",
    "  # concatenate month .txt files into one file for the year\n",
    "  os.system(\"cat \" + year + \"-*.txt > \" + keyword_eng + \"_\" + year + \"-all.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape random sample of all tweets from given year\n",
    "def scrape_tweets_general_year(year: str):\n",
    "    # 28 day months\n",
    "    scrape_sampled_tweets(year,[\"02\"], 28)    # omit leap year 29th days for simplicity...?\n",
    "\n",
    "    # 30 day months\n",
    "    months_30 = [\"04\",\"06\",\"09\",\"11\"]\n",
    "    scrape_sampled_tweets(year,months_30, 30)\n",
    "\n",
    "    # 31 day months\n",
    "    months_31 = [\"01\",\"03\",\"05\",\"07\",\"08\",\"10\",\"12\"]\n",
    "    scrape_sampled_tweets(year,months_31, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_tweets_general_year(\"2022\")\n",
    "concatenate_txt_files(\"2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape all tweets containing keyword in given year\n",
    "def scrape_tweets_keyword(year: str, keyword_jp: str, keyword_eng: str):\n",
    "    command = 'twscrape search \"' + keyword_jp + ' since:' + year + '-01-01_00:00:00_UTC lang:ja\"　> ' + keyword_eng + '_' + year + '.txt'\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_tweets_keyword(\"2022\", \"在日コリアン\", \"zainichi_test\")\n",
    "concatenate_txt_files(\"2022\", \"zainichi_test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-hw276cHk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
