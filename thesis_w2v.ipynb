{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from thesis_preprocess.ipynb\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "import json\n",
    "import MeCab\n",
    "import import_ipynb\n",
    "import thesis_preprocess\n",
    "from stopwords.stopwords_ja import stop_words\n",
    "from stopwords.stopwords_slothlib import stop_words_2\n",
    "\n",
    "# word2vec\n",
    "import gensim, logging\n",
    "\n",
    "# plotting\n",
    "from sklearn.manifold import TSNE               \n",
    "import numpy as np                \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Tokenize Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize cleaned tweets into words\n",
    "def tokenize_w2v(text):\n",
    "    mt = MeCab.Tagger(\"-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\")\n",
    "    parsed = mt.parseToNode(text)\n",
    "    components = []\n",
    "    \n",
    "    while parsed:\n",
    "        word = parsed.surface\n",
    "        pos = parsed.feature.split(\",\")[0]\n",
    "\n",
    "        # remove beg/end tokens, particles, fillers, auxiliary bound prefixes/endings\n",
    "        exclude_pos = ['BOS/EOS', '助詞', 'フィラー', '接頭詞', '助動詞']\n",
    "        if pos not in exclude_pos: components.append(word)\n",
    "        parsed = parsed.next\n",
    "    \n",
    "    # remove stopwords\n",
    "    components = [token for token in components if ((not token in stop_words) and (not token in stop_words_2))]\n",
    "    \n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess and tokenize with w2v-specific tokenize function\n",
    "def preprocess_tokenize_all_unique(filename, year):\n",
    "    tokens = []\n",
    "    tweets = thesis_preprocess.get_unique_tweets(filename, year)\n",
    "    for tweet in tweets:\n",
    "        processed = thesis_preprocess.preprocess(tweet)            \n",
    "        components = tokenize_w2v(processed)\n",
    "        tokens.append(components)\n",
    "\n",
    "    return tokens, tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_15, tweets_15 = preprocess_tokenize_all_unique(\"datasets_general_years/2015-all.txt\",\"2015\")\n",
    "thesis_preprocess.save_to_csv(tokens_15,\"saved_tokens_unique/2015-all.csv\")\n",
    "thesis_preprocess.save_to_csv(tweets_15,\"saved_tweets_unique/2015-all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_22, tweets_22 = preprocess_tokenize_all_unique(\"datasets_general_years/2022-all.txt\",\"2022\")\n",
    "thesis_preprocess.save_to_csv(tokens_22,\"saved_tokens_unique/2022-all.csv\")\n",
    "thesis_preprocess.save_to_csv(tweets_22,\"saved_tweets_unique/2022-all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and save word2vec model for given year\n",
    "def run_word2vec(year, tokens):\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    model = gensim.models.Word2Vec(tokens, min_count=5)\n",
    "    model.save(\"saved_w2v_models_unique/w2v_model_\" + year)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 22:28:41,599 : INFO : collecting all words and their counts\n",
      "2024-04-10 22:28:41,601 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2024-04-10 22:28:41,616 : INFO : PROGRESS: at sentence #10000, processed 58962 words, keeping 19405 word types\n",
      "2024-04-10 22:28:41,645 : INFO : PROGRESS: at sentence #20000, processed 117050 words, keeping 30132 word types\n",
      "2024-04-10 22:28:41,663 : INFO : PROGRESS: at sentence #30000, processed 175559 words, keeping 38413 word types\n",
      "2024-04-10 22:28:41,694 : INFO : PROGRESS: at sentence #40000, processed 233405 words, keeping 45727 word types\n",
      "2024-04-10 22:28:41,717 : INFO : PROGRESS: at sentence #50000, processed 292013 words, keeping 52151 word types\n",
      "2024-04-10 22:28:41,733 : INFO : PROGRESS: at sentence #60000, processed 350103 words, keeping 57989 word types\n",
      "2024-04-10 22:28:41,749 : INFO : PROGRESS: at sentence #70000, processed 409158 words, keeping 63457 word types\n",
      "2024-04-10 22:28:41,772 : INFO : PROGRESS: at sentence #80000, processed 467828 words, keeping 68530 word types\n",
      "2024-04-10 22:28:41,788 : INFO : PROGRESS: at sentence #90000, processed 526433 words, keeping 73361 word types\n",
      "2024-04-10 22:28:41,801 : INFO : PROGRESS: at sentence #100000, processed 583913 words, keeping 77871 word types\n",
      "2024-04-10 22:28:41,815 : INFO : PROGRESS: at sentence #110000, processed 641903 words, keeping 82288 word types\n",
      "2024-04-10 22:28:41,828 : INFO : PROGRESS: at sentence #120000, processed 700757 words, keeping 86535 word types\n",
      "2024-04-10 22:28:41,865 : INFO : PROGRESS: at sentence #130000, processed 759852 words, keeping 90575 word types\n",
      "2024-04-10 22:28:41,882 : INFO : PROGRESS: at sentence #140000, processed 817729 words, keeping 94553 word types\n",
      "2024-04-10 22:28:41,899 : INFO : PROGRESS: at sentence #150000, processed 877010 words, keeping 98295 word types\n",
      "2024-04-10 22:28:41,927 : INFO : PROGRESS: at sentence #160000, processed 936243 words, keeping 102041 word types\n",
      "2024-04-10 22:28:41,946 : INFO : PROGRESS: at sentence #170000, processed 994500 words, keeping 105497 word types\n",
      "2024-04-10 22:28:41,964 : INFO : PROGRESS: at sentence #180000, processed 1053093 words, keeping 108896 word types\n",
      "2024-04-10 22:28:41,981 : INFO : PROGRESS: at sentence #190000, processed 1110803 words, keeping 112124 word types\n",
      "2024-04-10 22:28:42,014 : INFO : PROGRESS: at sentence #200000, processed 1169204 words, keeping 115404 word types\n",
      "2024-04-10 22:28:42,037 : INFO : PROGRESS: at sentence #210000, processed 1227338 words, keeping 118520 word types\n",
      "2024-04-10 22:28:42,053 : INFO : PROGRESS: at sentence #220000, processed 1286638 words, keeping 121621 word types\n",
      "2024-04-10 22:28:42,069 : INFO : PROGRESS: at sentence #230000, processed 1345012 words, keeping 124673 word types\n",
      "2024-04-10 22:28:42,085 : INFO : PROGRESS: at sentence #240000, processed 1403473 words, keeping 127530 word types\n",
      "2024-04-10 22:28:42,109 : INFO : PROGRESS: at sentence #250000, processed 1462197 words, keeping 130522 word types\n",
      "2024-04-10 22:28:42,127 : INFO : PROGRESS: at sentence #260000, processed 1519314 words, keeping 133467 word types\n",
      "2024-04-10 22:28:42,144 : INFO : PROGRESS: at sentence #270000, processed 1578286 words, keeping 136343 word types\n",
      "2024-04-10 22:28:42,161 : INFO : PROGRESS: at sentence #280000, processed 1636347 words, keeping 139018 word types\n",
      "2024-04-10 22:28:42,176 : INFO : PROGRESS: at sentence #290000, processed 1694981 words, keeping 141815 word types\n",
      "2024-04-10 22:28:42,192 : INFO : PROGRESS: at sentence #300000, processed 1752462 words, keeping 144485 word types\n",
      "2024-04-10 22:28:42,208 : INFO : PROGRESS: at sentence #310000, processed 1811006 words, keeping 147162 word types\n",
      "2024-04-10 22:28:42,235 : INFO : PROGRESS: at sentence #320000, processed 1870330 words, keeping 149948 word types\n",
      "2024-04-10 22:28:42,251 : INFO : PROGRESS: at sentence #330000, processed 1929595 words, keeping 152581 word types\n",
      "2024-04-10 22:28:42,269 : INFO : PROGRESS: at sentence #340000, processed 1988985 words, keeping 155238 word types\n",
      "2024-04-10 22:28:42,301 : INFO : PROGRESS: at sentence #350000, processed 2047152 words, keeping 157809 word types\n",
      "2024-04-10 22:28:42,318 : INFO : PROGRESS: at sentence #360000, processed 2105471 words, keeping 160421 word types\n",
      "2024-04-10 22:28:42,334 : INFO : PROGRESS: at sentence #370000, processed 2163025 words, keeping 162849 word types\n",
      "2024-04-10 22:28:42,350 : INFO : PROGRESS: at sentence #380000, processed 2220504 words, keeping 165269 word types\n",
      "2024-04-10 22:28:42,371 : INFO : PROGRESS: at sentence #390000, processed 2279474 words, keeping 167747 word types\n",
      "2024-04-10 22:28:42,402 : INFO : PROGRESS: at sentence #400000, processed 2337455 words, keeping 170151 word types\n",
      "2024-04-10 22:28:42,420 : INFO : PROGRESS: at sentence #410000, processed 2395829 words, keeping 172501 word types\n",
      "2024-04-10 22:28:42,441 : INFO : PROGRESS: at sentence #420000, processed 2454880 words, keeping 174803 word types\n",
      "2024-04-10 22:28:42,459 : INFO : PROGRESS: at sentence #430000, processed 2512394 words, keeping 177133 word types\n",
      "2024-04-10 22:28:42,475 : INFO : PROGRESS: at sentence #440000, processed 2571847 words, keeping 179535 word types\n",
      "2024-04-10 22:28:42,490 : INFO : PROGRESS: at sentence #450000, processed 2630446 words, keeping 181717 word types\n",
      "2024-04-10 22:28:42,519 : INFO : PROGRESS: at sentence #460000, processed 2687986 words, keeping 183866 word types\n",
      "2024-04-10 22:28:42,566 : INFO : PROGRESS: at sentence #470000, processed 2746580 words, keeping 186115 word types\n",
      "2024-04-10 22:28:42,595 : INFO : PROGRESS: at sentence #480000, processed 2805423 words, keeping 188329 word types\n",
      "2024-04-10 22:28:42,599 : INFO : collected 188830 word types from a corpus of 2818484 raw words and 482200 sentences\n",
      "2024-04-10 22:28:42,599 : INFO : Creating a fresh vocabulary\n",
      "2024-04-10 22:28:42,723 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 43357 unique words (22.96% of original 188830, drops 145473)', 'datetime': '2024-04-10T22:28:42.723864', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-14.4.1-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-04-10 22:28:42,724 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 2603503 word corpus (92.37% of original 2818484, drops 214981)', 'datetime': '2024-04-10T22:28:42.724620', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-14.4.1-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-04-10 22:28:42,874 : INFO : deleting the raw counts dictionary of 188830 items\n",
      "2024-04-10 22:28:42,877 : INFO : sample=0.001 downsamples 11 most-common words\n",
      "2024-04-10 22:28:42,878 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 2554710.0332633955 word corpus (98.1%% of prior 2603503)', 'datetime': '2024-04-10T22:28:42.878643', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-14.4.1-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2024-04-10 22:28:43,155 : INFO : estimated required memory for 43357 words and 100 dimensions: 56364100 bytes\n",
      "2024-04-10 22:28:43,156 : INFO : resetting layer weights\n",
      "2024-04-10 22:28:43,328 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-04-10T22:28:43.328028', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-14.4.1-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2024-04-10 22:28:43,328 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 43357 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-04-10T22:28:43.328663', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-14.4.1-x86_64-i386-64bit', 'event': 'train'}\n",
      "2024-04-10 22:28:44,351 : INFO : EPOCH 0 - PROGRESS: at 58.17% examples, 1480472 words/s, in_qsize 5, out_qsize 0\n",
      "2024-04-10 22:28:45,041 : INFO : EPOCH 0: training on 2818484 raw words (2554753 effective words) took 1.7s, 1508828 effective words/s\n",
      "2024-04-10 22:28:46,052 : INFO : EPOCH 1 - PROGRESS: at 63.87% examples, 1627045 words/s, in_qsize 5, out_qsize 0\n",
      "2024-04-10 22:28:46,622 : INFO : EPOCH 1: training on 2818484 raw words (2554688 effective words) took 1.6s, 1624807 effective words/s\n",
      "2024-04-10 22:28:47,648 : INFO : EPOCH 2 - PROGRESS: at 31.89% examples, 801641 words/s, in_qsize 6, out_qsize 1\n",
      "2024-04-10 22:28:48,649 : INFO : EPOCH 2 - PROGRESS: at 82.63% examples, 1045815 words/s, in_qsize 5, out_qsize 0\n",
      "2024-04-10 22:28:48,966 : INFO : EPOCH 2: training on 2818484 raw words (2554717 effective words) took 2.3s, 1093927 effective words/s\n",
      "2024-04-10 22:28:49,973 : INFO : EPOCH 3 - PROGRESS: at 55.34% examples, 1412741 words/s, in_qsize 5, out_qsize 0\n",
      "2024-04-10 22:28:50,651 : INFO : EPOCH 3: training on 2818484 raw words (2554761 effective words) took 1.7s, 1522349 effective words/s\n",
      "2024-04-10 22:28:51,666 : INFO : EPOCH 4 - PROGRESS: at 59.94% examples, 1520877 words/s, in_qsize 5, out_qsize 0\n",
      "2024-04-10 22:28:52,338 : INFO : EPOCH 4: training on 2818484 raw words (2554804 effective words) took 1.7s, 1521522 effective words/s\n",
      "2024-04-10 22:28:52,339 : INFO : Word2Vec lifecycle event {'msg': 'training on 14092420 raw words (12773723 effective words) took 9.0s, 1417699 effective words/s', 'datetime': '2024-04-10T22:28:52.339267', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-14.4.1-x86_64-i386-64bit', 'event': 'train'}\n",
      "2024-04-10 22:28:52,339 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=43357, vector_size=100, alpha=0.025>', 'datetime': '2024-04-10T22:28:52.339749', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-14.4.1-x86_64-i386-64bit', 'event': 'created'}\n",
      "2024-04-10 22:28:52,340 : INFO : Word2Vec lifecycle event {'fname_or_handle': 'saved_w2v_models_unique/w2v_model_2015', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2024-04-10T22:28:52.340225', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-14.4.1-x86_64-i386-64bit', 'event': 'saving'}\n",
      "2024-04-10 22:28:52,342 : INFO : not storing attribute cum_table\n",
      "2024-04-10 22:28:52,548 : INFO : saved saved_w2v_models_unique/w2v_model_2015\n"
     ]
    }
   ],
   "source": [
    "# train and save word2vec model for 2015 \n",
    "model_2015 = run_word2vec(\"2015\", tokens_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and save word2vec model for 2022\n",
    "model_2022 = run_word2vec(\"2022\", tokens_22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Similar Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_words(keyword:str, model, positive=[], negative=[], topn=10):\n",
    "    if len(positive) == 0: positive = keyword\n",
    "\n",
    "    print(\"\\nSimilar words to \" + keyword + \": 2015\")\n",
    "    try:\n",
    "        words = model.wv.most_similar(positive=positive, negative=negative, topn=topn)\n",
    "        for w in words:\n",
    "            print(w[0])\n",
    "    except:\n",
    "        print(\"Error\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_similar_words(keyword:str, model_2015, model_2022, positive=[], negative=[], topn=10):\n",
    "    if len(positive) == 0: positive = keyword\n",
    "\n",
    "    # 2015\n",
    "    print(\"\\nSimilar words to \" + keyword + \": 2015\")\n",
    "    try:\n",
    "        words_15 = model_2015.wv.most_similar(positive=positive, negative=negative, topn=topn)\n",
    "        for w in words_15:\n",
    "            print(w[0])\n",
    "    except:\n",
    "        print(\"Error\\n\")\n",
    "\n",
    "    # 2022\n",
    "    print(\"\\nSimilar words to \" + keyword + \": 2022\")\n",
    "    try:\n",
    "        words_22 = model_2022.wv.most_similar(positive=positive, negative=negative, topn=topn)\n",
    "        for w in words_22:\n",
    "            print(w[0])\n",
    "    except:\n",
    "        print(\"Error\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-10 22:31:26,421 : INFO : loading Word2Vec object from saved_w2v_models_unique/w2v_model_2015\n",
      "2024-04-10 22:31:26,687 : INFO : loading wv recursively from saved_w2v_models_unique/w2v_model_2015.wv.* with mmap=None\n",
      "2024-04-10 22:31:26,689 : INFO : setting ignored attribute cum_table to None\n",
      "2024-04-10 22:31:27,073 : INFO : Word2Vec lifecycle event {'fname': 'saved_w2v_models_unique/w2v_model_2015', 'datetime': '2024-04-10T22:31:27.073595', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-14.4.1-x86_64-i386-64bit', 'event': 'loaded'}\n",
      "2024-04-10 22:31:27,076 : INFO : loading Word2Vec object from saved_w2v_models_unique/w2v_model_2022\n",
      "2024-04-10 22:31:27,337 : INFO : loading wv recursively from saved_w2v_models_unique/w2v_model_2022.wv.* with mmap=None\n",
      "2024-04-10 22:31:27,347 : INFO : setting ignored attribute cum_table to None\n",
      "2024-04-10 22:31:27,670 : INFO : Word2Vec lifecycle event {'fname': 'saved_w2v_models_unique/w2v_model_2022', 'datetime': '2024-04-10T22:31:27.670261', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-14.4.1-x86_64-i386-64bit', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "model_2015 = gensim.models.Word2Vec.load(\"saved_w2v_models_unique/w2v_model_2015\")\n",
    "model_2022 = gensim.models.Word2Vec.load(\"saved_w2v_models_unique/w2v_model_2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_similar_words(\"在日\", model_2015)\n",
    "get_similar_words(\"アイヌ\", model_2015)\n",
    "get_similar_words(\"沖縄\", model_2015, positive=[\"沖縄\",\"日本人\"])\n",
    "get_similar_words(\"琉球\", model_2015, positive=[\"琉球\",\"日本人\"])\n",
    "get_similar_words(\"ハフ\", model_2015, positive=[\"ハフ\",'日本人'], negative=[\"髪\",\"服\"])\n",
    "get_similar_words(\"ベトナム\", model_2015)\n",
    "get_similar_words(\"フィリピン\", model_2015)\n",
    "get_similar_words(\"外人\", model_2015)\n",
    "get_similar_words(\"外国人\", model_2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similar words to 在日: 2015\n",
      "違憲\n",
      "発覚\n",
      "公正\n",
      "首相\n",
      "政策\n",
      "自民\n",
      "野党\n",
      "博愛\n",
      "安倍\n",
      "集団的自衛権\n",
      "\n",
      "Similar words to 在日: 2022\n",
      "植民地\n",
      "習近平\n",
      "反日カルト\n",
      "毀損\n",
      "我が国\n",
      "人権問題\n",
      "日本の政治\n",
      "反日\n",
      "留学生\n",
      "国益\n",
      "\n",
      "Similar words to アイヌ: 2015\n",
      "Error\n",
      "\n",
      "\n",
      "Similar words to アイヌ: 2022\n",
      "オウム\n",
      "朝鮮\n",
      "死後\n",
      "貶める\n",
      "表現の自由\n",
      "公正\n",
      "言説\n",
      "一族\n",
      "仏教\n",
      "諸悪の根源\n",
      "\n",
      "Similar words to 沖縄: 2015\n",
      "韓国\n",
      "アメリカ\n",
      "文化\n",
      "中国\n",
      "日本\n",
      "米軍\n",
      "海外\n",
      "報道\n",
      "ドイツ\n",
      "産経\n",
      "\n",
      "Similar words to 沖縄: 2022\n",
      "アメリカ\n",
      "外国\n",
      "移住\n",
      "台湾\n",
      "中国\n",
      "住む\n",
      "留学\n",
      "日本\n",
      "イギリス\n",
      "韓国\n",
      "\n",
      "Similar words to 琉球: 2015\n",
      "イスラム\n",
      "痛烈\n",
      "韓国人\n",
      "北朝鮮\n",
      "外国\n",
      "中韓\n",
      "ジャナリスト\n",
      "フランス\n",
      "人質事件\n",
      "訪日\n",
      "\n",
      "Similar words to 琉球: 2022\n",
      "朝鮮人\n",
      "真珠湾攻撃\n",
      "中国人\n",
      "中国共産党\n",
      "軍事作戦\n",
      "大国\n",
      "称賛\n",
      "時代遅れ\n",
      "生ん\n",
      "橋下徹\n",
      "\n",
      "Similar words to ハフ: 2015\n",
      "国会\n",
      "団体\n",
      "成立\n",
      "安保法案\n",
      "朝日新聞デジタル\n",
      "調査\n",
      "安保\n",
      "支援\n",
      "規制\n",
      "ニュス\n",
      "\n",
      "Similar words to ハフ: 2022\n",
      "記者\n",
      "代表\n",
      "出身\n",
      "ウクライナ\n",
      "維新\n",
      "国葬\n",
      "大統領\n",
      "報道\n",
      "氏\n",
      "安倍さん\n",
      "\n",
      "Similar words to ベトナム: 2015\n",
      "審\n",
      "小西\n",
      "考\n",
      "刑務所\n",
      "ダウ平均\n",
      "名簿\n",
      "言い渡さ\n",
      "聖地\n",
      "特別区\n",
      "国籍\n",
      "\n",
      "Similar words to ベトナム: 2022\n",
      "江戸時代\n",
      "隈研吾\n",
      "中東\n",
      "締結\n",
      "西欧\n",
      "半島\n",
      "起源\n",
      "内戦\n",
      "南米\n",
      "美的\n",
      "\n",
      "Similar words to フィリピン: 2015\n",
      "メキシコ\n",
      "サムスン\n",
      "愛国\n",
      "方位\n",
      "織田信成\n",
      "放射能汚染\n",
      "天皇陛下\n",
      "倒壊\n",
      "二酸化炭素\n",
      "闘争\n",
      "\n",
      "Similar words to フィリピン: 2022\n",
      "郊外\n",
      "北方\n",
      "ロンドン\n",
      "逃走\n",
      "沿線\n",
      "宮殿\n",
      "人情\n",
      "発祥\n",
      "江戸時代\n",
      "白川郷\n",
      "\n",
      "Similar words to 外人: 2015\n",
      "間違える\n",
      "噛み合っ\n",
      "通じる\n",
      "汚く\n",
      "ウケ\n",
      "困惑\n",
      "錯覚\n",
      "ヘラヘラ\n",
      "自己嫌悪\n",
      "叩か\n",
      "\n",
      "Similar words to 外人: 2022\n",
      "ヅラ\n",
      "あらわれ\n",
      "呼ばわり\n",
      "引っ掛かる\n",
      "ジジイ\n",
      "ホモ\n",
      "逆ギレ\n",
      "無いっ\n",
      "キレる\n",
      "言い出し\n",
      "\n",
      "Similar words to 外国人: 2015\n",
      "前年\n",
      "研究者\n",
      "デザイナ\n",
      "痛烈\n",
      "オナ\n",
      "記者\n",
      "スタンダド\n",
      "相次ぐ\n",
      "伝統\n",
      "専門家\n",
      "\n",
      "Similar words to 外国人: 2022\n",
      "外国\n",
      "消費税\n",
      "違反\n",
      "要求\n",
      "軍事\n",
      "逮捕\n",
      "他国\n",
      "中国\n",
      "犯罪\n",
      "増税\n"
     ]
    }
   ],
   "source": [
    "compare_similar_words(\"在日\", model_2015, model_2022)\n",
    "compare_similar_words(\"アイヌ\", model_2015, model_2022)\n",
    "compare_similar_words(\"沖縄\", model_2015, model_2022, positive=[\"沖縄\",\"日本人\"])\n",
    "compare_similar_words(\"琉球\", model_2015, model_2022, positive=[\"琉球\",\"日本人\"])\n",
    "compare_similar_words(\"ハフ\", model_2015, model_2022, positive=[\"ハフ\",\"日本人\"], negative=[\"髪\",\"服\"])\n",
    "compare_similar_words(\"ベトナム\", model_2015, model_2022)\n",
    "compare_similar_words(\"フィリピン\", model_2015, model_2022)\n",
    "compare_similar_words(\"外人\", model_2015, model_2022)\n",
    "compare_similar_words(\"外国人\", model_2015, model_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
