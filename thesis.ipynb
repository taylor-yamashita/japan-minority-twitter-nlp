{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import json\n",
    "import MeCab\n",
    "import demoji\n",
    "import re\n",
    "from stop_words import stop_words\n",
    "import gensim, logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean and Tokenize Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize with mecab\n",
    "mt = MeCab.Tagger(\"-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\")\n",
    "\n",
    "# store results and exception tweets\n",
    "tokens = []\n",
    "retweets = []\n",
    "not_parsed = []\n",
    "\n",
    "# iterate through tweets\n",
    "with open('2022-all.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        tweet = json.loads(line)\n",
    "    \n",
    "        if line == None or tweet == None:\n",
    "            not_parsed.append((line, tweet))\n",
    "            print(\"Parsing error: \", line, tweet)\n",
    "        elif tweet['retweetedTweet']:\n",
    "            retweets.append(tweet)\n",
    "            print(\"Retweet: \", tweet['id'])\n",
    "        else: \n",
    "            # clean tweet content\n",
    "            tweet_text = tweet['rawContent'] # note: need other prop for over 140 char?\n",
    "            remove_emojis = demoji.replace(tweet_text, \"\")\n",
    "            remove_more_emojis = re.sub(\"([\\uD83E-\\uD83E])+\", \"\", remove_emojis)\n",
    "            remove_newlines = re.sub(\"(\\n)+\", \"\", remove_more_emojis)\n",
    "            remove_usernames = re.sub(\"@([a-zA-Z0-9_]+)\", \"\", remove_newlines)\n",
    "            remove_hashtags = re.sub(\"#([a-zA-Z0-9_ぁ-んァ-ン一-龠]+)\", \"\", remove_usernames)\n",
    "            remove_links = re.sub(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \"\", remove_hashtags)\n",
    "            remove_punc = re.sub(\"([-.,;\\\"\\'!?~@#$%^&*():\\{\\}\\[\\]\\/\\\\\\\\]+)\", \"\", remove_links)\n",
    "            remove_jp_punc = re.sub(\"([\\uFF01-\\uFF0F\\uFF1A-\\uFF20\\uFF3B-\\uFF40\\uFF5B-\\uFF65\\uFF9E-\\uFFEE\\u3000-\\u303F]+)\", \"\", remove_punc)\n",
    "            remove_geo_shapes = re.sub(\"([\\u25A0-\\u25FF])+\", \"\", remove_jp_punc)\n",
    "            remove_misc_symbols = re.sub(\"([\\u2600-\\u26FF])+\", \"\", remove_geo_shapes)\n",
    "\n",
    "            # tokenize with mecab\n",
    "            parsed = mt.parseToNode(remove_misc_symbols)\n",
    "            components = []\n",
    "            while parsed:\n",
    "                components.append(parsed.surface)\n",
    "                parsed = parsed.next\n",
    "            components = [token for token in components if not token in stop_words]\n",
    "            tokens.append(components)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-03 22:13:15,364 : INFO : collecting all words and their counts\n",
      "2023-11-03 22:13:15,365 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2023-11-03 22:13:15,366 : INFO : collected 805 word types from a corpus of 1172 raw words and 100 sentences\n",
      "2023-11-03 22:13:15,366 : INFO : Creating a fresh vocabulary\n",
      "2023-11-03 22:13:15,367 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=3 retains 61 unique words (7.58% of original 805, drops 744)', 'datetime': '2023-11-03T22:13:15.367696', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.5-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-11-03 22:13:15,369 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 323 word corpus (27.56% of original 1172, drops 849)', 'datetime': '2023-11-03T22:13:15.369444', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.5-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-11-03 22:13:15,370 : INFO : deleting the raw counts dictionary of 805 items\n",
      "2023-11-03 22:13:15,371 : INFO : sample=0.001 downsamples 61 most-common words\n",
      "2023-11-03 22:13:15,371 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 95.14527703542554 word corpus (29.5%% of prior 323)', 'datetime': '2023-11-03T22:13:15.371708', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.5-x86_64-i386-64bit', 'event': 'prepare_vocab'}\n",
      "2023-11-03 22:13:15,373 : INFO : estimated required memory for 61 words and 100 dimensions: 79300 bytes\n",
      "2023-11-03 22:13:15,373 : INFO : resetting layer weights\n",
      "2023-11-03 22:13:15,374 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2023-11-03T22:13:15.374530', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.5-x86_64-i386-64bit', 'event': 'build_vocab'}\n",
      "2023-11-03 22:13:15,375 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 61 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-11-03T22:13:15.374992', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.5-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-11-03 22:13:15,378 : INFO : EPOCH 0: training on 1172 raw words (98 effective words) took 0.0s, 238298 effective words/s\n",
      "2023-11-03 22:13:15,381 : INFO : EPOCH 1: training on 1172 raw words (89 effective words) took 0.0s, 182986 effective words/s\n",
      "2023-11-03 22:13:15,382 : INFO : EPOCH 2: training on 1172 raw words (84 effective words) took 0.0s, 265263 effective words/s\n",
      "2023-11-03 22:13:15,385 : INFO : EPOCH 3: training on 1172 raw words (91 effective words) took 0.0s, 156335 effective words/s\n",
      "2023-11-03 22:13:15,390 : INFO : EPOCH 4: training on 1172 raw words (100 effective words) took 0.0s, 6332320 effective words/s\n",
      "2023-11-03 22:13:15,390 : INFO : Word2Vec lifecycle event {'msg': 'training on 5860 raw words (462 effective words) took 0.0s, 29867 effective words/s', 'datetime': '2023-11-03T22:13:15.390785', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.5-x86_64-i386-64bit', 'event': 'train'}\n",
      "2023-11-03 22:13:15,391 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec<vocab=61, vector_size=100, alpha=0.025>', 'datetime': '2023-11-03T22:13:15.391077', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-13.5-x86_64-i386-64bit', 'event': 'created'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('来', 0.2849620580673218), ('お願い', 0.24154554307460785), ('おはよう', 0.20102809369564056), ('大切', 0.1925160437822342), ('日本', 0.17427216470241547), ('よかっ', 0.16761992871761322), ('欲しい', 0.13868466019630432), ('だけ', 0.1273307055234909), ('°', 0.10057535767555237), ('ありがとう', 0.09638050198554993)]\n"
     ]
    }
   ],
   "source": [
    "# word2vec\n",
    "\n",
    "# set up logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# train word2vec\n",
    "model = gensim.models.Word2Vec(tokens, min_count=10)\n",
    "\n",
    "# check similarity given by trained model\n",
    "sim = model.wv.most_similar('今日')\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
