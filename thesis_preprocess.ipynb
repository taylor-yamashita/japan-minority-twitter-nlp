{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import mojimoji\n",
    "import demoji\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess tweet content\n",
    "def preprocess(text):    \n",
    "    # convert half-width/full-width chars \n",
    "    text = text.lower()\n",
    "    text = mojimoji.zen_to_han(text, kana=False)\n",
    "    text = mojimoji.han_to_zen(text, digit=False, ascii=False)\n",
    "    \n",
    "    # convert jp punctuation (code from https://colab.research.google.com/drive/1bX-JyY4xmCm_RFkJg3QNcthUvEJaBghP)\n",
    "    text = text.translate(str.maketrans({\n",
    "        '!': '！', '\"': '”', '#': '＃', '$': '＄', '%': '％', '&': '＆', '\\'': '’',\n",
    "        '(': '（', ')': '）', '*': '＊', '+': '＋', ',': '，', '-': '−', '.': '．',\n",
    "        '/': '／', ':': '：', ';': '；', '<': '＜', '=': '＝', '>': '＞', '?': '？',\n",
    "        '@': '＠', '[': '［', '\\\\': '＼', ']': '］', '^': '＾', '_': '＿', '`': '｀',\n",
    "        '{': '｛', '|': '｜', '}': '｝'\n",
    "        }))\n",
    "    zenkaku_leftsingle = b'\\xe2\\x80\\x98'.decode('utf-8')\n",
    "    text = re.sub('[’´｀]', zenkaku_leftsingle, text)\n",
    "    \n",
    "    # remove twitter-specific strings (handles, hashtags, etc.)\n",
    "    text = re.sub(\"@([a-zA-Z0-9_]+)\", \"\", text)\n",
    "    text = re.sub(\"#([a-zA-Z0-9_ぁ-んァ-ン一-龠]+)\", \"\", text)\n",
    "    text = re.sub(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\", \"\", text)\n",
    "\n",
    "    # remove emojis\n",
    "    text = demoji.replace(text, \"\")\n",
    "    text = re.sub(\"([\\uD83E-\\uD83E])+\", \"\", text)\n",
    "\n",
    "    # remove punctuation and whitespace\n",
    "    text = re.sub(\"([^一-龯ぁ-んァ-ン])+\",\"\",text)  \n",
    "    text = re.sub(\"(\\s)+\", \"\", text)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_tweets(filename, year):\n",
    "    tweets = []\n",
    "    # iterate through tweets\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            if line == None or tweet == None:\n",
    "                print(\"Parsing error: \", line, tweet)\n",
    "            elif tweet['retweetedTweet']:\n",
    "                print(\"Retweet: \", tweet['id'])\n",
    "            elif int(tweet['date'].split(\"-\")[0]) < int(year) + 1: \n",
    "                tweet_text = tweet['rawContent'] # note: need other prop for over 140 char?\n",
    "                tweets.append(tweet_text)\n",
    "    file.close()\n",
    "    tweets_unique = list(set(tweets))\n",
    "    print(len(tweets))\n",
    "    print(len(tweets_unique))\n",
    "    \n",
    "    return tweets_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-hw276cHk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
