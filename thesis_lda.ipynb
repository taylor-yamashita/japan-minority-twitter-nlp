{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from thesis_preprocess.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:23: DeprecationWarning: invalid escape sequence '\\('\n",
      "<string>:31: DeprecationWarning: invalid escape sequence '\\s'\n"
     ]
    }
   ],
   "source": [
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "# tokenization\n",
    "import json\n",
    "import MeCab\n",
    "import import_ipynb\n",
    "import thesis_preprocess\n",
    "from stopwords_ja import stop_words\n",
    "from stopwords_slothlib import stop_words_2\n",
    "\n",
    "# lda topic modeling\n",
    "import gensim, logging\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize cleaned tweets into words\n",
    "def tokenize(text):\n",
    "    mt = MeCab.Tagger(\"-d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\")\n",
    "    parsed = mt.parseToNode(text)\n",
    "    components = []\n",
    "    \n",
    "    while parsed:\n",
    "        word = parsed.surface\n",
    "        pos = parsed.feature.split(\",\")[0]\n",
    "\n",
    "        # for lda, we only want nouns, verbs, adjectives\n",
    "        include_pos = [\"名詞\", \"動詞\", \"形容詞\"]\n",
    "        if pos in include_pos: components.append(word)\n",
    "        parsed = parsed.next\n",
    "    \n",
    "    # remove stopwords\n",
    "    components = [token for token in components if ((not token in stop_words) and (not token in stop_words_2))]\n",
    "    \n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run preprocessing and tokenization for tweets from given .txt file\n",
    "def preprocess_tokenize_all(filename, year):\n",
    "    # store results and exception tweets\n",
    "    tokens = []\n",
    "    retweets = []\n",
    "    not_parsed = []\n",
    "\n",
    "    # iterate through tweets, preprocess and tokenize\n",
    "    with open(filename, 'r') as file:\n",
    "        for line in file:\n",
    "            tweet = json.loads(line)\n",
    "            print(int(year) + 1)\n",
    "            if line == None or tweet == None:\n",
    "                not_parsed.append((line, tweet))\n",
    "                print(\"Parsing error: \", line, tweet)\n",
    "            elif tweet['retweetedTweet']:\n",
    "                retweets.append(tweet)\n",
    "                print(\"Retweet: \", tweet['id'])\n",
    "            # filter out 2024 sponsored(?) tweets\n",
    "            elif int(tweet['date'].split(\"-\")[0]) > int(year) + 1: \n",
    "                tweet_text = tweet['rawContent'] # note: need other prop for over 140 char?\n",
    "                processed = preprocess(tweet_text)            \n",
    "                components = tokenize(processed)\n",
    "                tokens.append(components)\n",
    "\n",
    "    file.close()\n",
    "    return tokens, retweets, not_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run for 2015\n",
    "# tokens_2015, retweets_2015, not_parsed_2015 = preprocess_tokenize_all(\"2015\")\n",
    "\n",
    "# # did we get retweets or errors?\n",
    "# print(len(retweets_2015))\n",
    "# print(len(not_parsed_2015))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run for 2022\n",
    "token_tweets_2022, retweets_2022, not_parsed_2022 = preprocess_tokenize_all(\"2022\")\n",
    "\n",
    "# did we get retweets or errors?\n",
    "print(len(retweets_2022))\n",
    "print(len(not_parsed_2022))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in filename you want to save data as, including '.csv'\n",
    "def save_to_csv(tweet_tokens, filename):\n",
    "    f = open(filename, 'w')\n",
    "    writer = csv.writer(f)\n",
    "    for tweet in tweet_tokens:\n",
    "        writer.writerow(tweet)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass in filename of csv you want to load, including '.csv'\n",
    "def load_from_csv(filename):\n",
    "    with open(filename, newline='') as f:\n",
    "        reader = csv.reader(f)\n",
    "        tweet_tokens = list(reader)\n",
    "    return tweet_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://lda.readthedocs.io/en/latest/getting_started.html\n",
    "# https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "# https://github.com/deankuo/Japan-Manifesto-Classification/blob/main/topic_modeling.ipynb\n",
    "# https://github.com/m3yrin/NTM/blob/master/LDA_jp.ipynb\n",
    "# https://tdual.hatenablog.com/entry/2018/04/09/133000#1LDA%E3%81%AE%E5%89%8D%E3%81%AB%E3%83%88%E3%83%94%E3%83%83%E3%82%AF%E3%83%A2%E3%83%87%E3%83%AB%E3%81%A8%E3%81%AF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and save word2vec model for given year\n",
    "def run_lda(filename, tweet_tokens, no_below=5, no_above=0.2):\n",
    "    # set up dictionary\n",
    "    dict = corpora.Dictionary(tweet_tokens)\n",
    "    dict.filter_extremes(no_below, no_above)\n",
    "    dict.compactify()\n",
    "\n",
    "    # set up corpus\n",
    "    corpus = [dict.doc2bow(w) for w in tweet_tokens]\n",
    "    test_size = int(len(corpus) * 0.1)\n",
    "    test_corpus = corpus[:test_size]\n",
    "    train_corpus = corpus[test_size:]   \n",
    "\n",
    "    # train and save lda model\n",
    "    logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "    lda = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dict, num_topics=20, passes=10, update_every=5)\n",
    "    lda.save(\"save_lda_model_\" + filename)\n",
    "    \n",
    "    return lda, dict, corpus, train_corpus, test_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading LdaModel object from thesis_lda_model_2022\n",
      "loading expElogbeta from thesis_lda_model_2022.expElogbeta.npy with mmap=None\n",
      "setting ignored attribute id2word to None\n",
      "setting ignored attribute dispatcher to None\n",
      "setting ignored attribute state to None\n",
      "LdaModel lifecycle event {'fname': 'thesis_lda_model_2022', 'datetime': '2024-03-17T10:28:38.384616', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-14.3.1-x86_64-i386-64bit', 'event': 'loaded'}\n",
      "loading LdaState object from thesis_lda_model_2022.state\n",
      "LdaState lifecycle event {'fname': 'thesis_lda_model_2022.state', 'datetime': '2024-03-17T10:28:38.407748', 'gensim': '4.3.2', 'python': '3.11.5 (main, Aug 24 2023, 15:18:16) [Clang 14.0.3 (clang-1403.0.22.14.1)]', 'platform': 'macOS-14.3.1-x86_64-i386-64bit', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "lda_2022_gen = gensim.models.LdaModel.load(\"save_lda_model_2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine topics\n",
    "def get_topic_words(lda, topic_id):\n",
    "    for t in lda.get_topic_terms(topic_id):\n",
    "        print(\"{}: {}\".format(d[t[0]], t[1]))\n",
    "\n",
    "def examine_topics(lda):\n",
    "    for t in range(10):\n",
    "        print(\"Topic # \",t)\n",
    "        get_topic_words(lda, t)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_train_test_results(lda, train_corpus, test_corpus):\n",
    "    # look at train set results\n",
    "    N = sum(count for doc in train_corpus for _, count in doc)\n",
    "    print(\"# of words in train corpus: \",N)\n",
    "    perplexity = np.exp2(-lda.log_perplexity(train_corpus))\n",
    "    print(\"perplexity(train):\", perplexity,\"\\n\")\n",
    "\n",
    "    # look at test set results\n",
    "    N = sum(count for doc in test_corpus for _, count in doc)\n",
    "    print(\"# of words in test corpus: \",N)\n",
    "    perplexity = np.exp2(-lda.log_perplexity(test_corpus))\n",
    "    print(\"perplexity(test):\", perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_overall_results(lda, corpus):\n",
    "    # look at overall perplexity and coherence score\n",
    "    print('\\nPerplexity: ', lda.log_perplexity(corpus))     # lower is better\n",
    "\n",
    "    coherence_model_lda = CoherenceModel(model=lda, texts=token_tweets_2022, dictionary=d, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('\\nCoherence Score: ', coherence_lda)     # higher is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_topics(lda, corpus, dict):\n",
    "    pyLDAvis.enable_notebook()\n",
    "    vis = pyLDAvis.gensim.prepare(lda, corpus, dict)\n",
    "    return vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "def format_topics_sentences(lda, corpus, tweet_tokens):\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # get main topic in each document\n",
    "    for i, row in enumerate(lda[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # for each document, get dominant topic, perc contribution and keywords \n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = lda.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = pd.concat([sent_topics_df,pd.Series([int(topic_num), round(prop_topic,4), topic_keywords])], ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # add original text to the end of the output\n",
    "    contents = pd.Series(tweet_tokens)\n",
    "    sent_topics_df = contents\n",
    "\n",
    "    # TODO: debug this line\n",
    "    # sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run this once we collect a keyword dataset\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda, corpus=corpus, texts=token_tweets_2022)\n",
    "\n",
    "# format and show\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group top 5 sentences under each topic\n",
    "sent_topics_sorteddf = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf = pd.concat([sent_topics_sorteddf, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# reset index    \n",
    "sent_topics_sorteddf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# format and show\n",
    "sent_topics_sorteddf.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "sent_topics_sorteddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num documents per topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# percentage documents for each topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# topic number, keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# concatenate column-wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# add column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# show\n",
    "df_dominant_topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis-hw276cHk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
